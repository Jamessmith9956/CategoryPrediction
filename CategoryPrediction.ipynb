{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Current Plan\n",
    "1. Create a function to calculate the distance between descriptions, use that function to naively classify new descriptions. probably looks something like a search function.\n",
    "2. Grab a text classification model of hugging face and fine-tune it on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup requirements, which aren't loading in the venv for some reason\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning \n",
    "The data is already pretty clean as far as non gramatical structures go. Removing all non-alphanumeric characters and lowercasing actually seems to reduce performance a bit on the embedding model, and these characters are allready stripped in the tokenization process for the naive models.\n",
    "\n",
    "There are some sanitisation libraries around, eg. pydantic or the NLTK library but i will stick to simple here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "\n",
    "with open('data/Datas.csv') as file:\n",
    "    data = pd.read_csv(file)\n",
    "\n",
    "#over cleaning the data hurts prerformance \n",
    "# Strip non alphanumeric characters and convert to lowercase\n",
    "data['Description'] = data['Description'].apply(lambda x: re.sub(r'[^a-zA-Z0-9\\s]', '', x))\n",
    "data['Description'] = data['Description'].apply(lambda x: x.lower())\n",
    "\n",
    "# \n",
    "data['Description'] = data['Description'].apply(lambda x: re.sub(r'&amp;', 'and', x))\n",
    "data['Description'] = data['Description'].apply(lambda x: re.sub(r' & ', 'and', x))\n",
    "\n",
    "#honestly it should all just get lost in the sauce \n",
    "\n",
    "# Change all Categories other than Food and Entertainment to Other\n",
    "#data['Category'] = ['Other' if category not in ['Food', 'Entertainment'] else category for category in data['Category']]\n",
    "\n",
    "\n",
    "#save to csv \n",
    "data.to_csv('data/cleaned_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation/Expansion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling and splitting\n",
    "Oversampling using a target minimum number of samples doesn't seem to work atm, but I'm out of time to debug it.\n",
    "Smote and AdaSynth are used for the embedded models further down, but they required some extra data to be sythesised to work well.\n",
    "having never done text generation in this way, I'm following [this guide](https://python.langchain.com/docs/modules/model_io/output_parsers/types/pydantic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training set into train, test and val sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "# class must have at least 3 samples to be split\n",
    "tmp = data.groupby('Category').filter(lambda x: len(x) <= 2)\n",
    "data = data.groupby('Category').filter(lambda x: len(x) > 2)\n",
    "train, test = train_test_split(data, test_size=0.2, stratify=data['Category'], random_state=42)\n",
    "#test = pd.concat([test, tmp], axis=0)\n",
    "train, val = train_test_split(train, test_size=0.3, stratify=train['Category'], random_state=77)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sythesising Data using models\n",
    "[using the guide](https://python.langchain.com/docs/modules/model_io/output_parsers/types/pydantic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MiniMA 3B model - requires cloud hosting\n",
    "import torch\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# MiniMA\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"GeneZC/MiniMA-3B\", use_fast=False)\n",
    "# GPU.\n",
    "model = AutoModelForCausalLM.from_pretrained(\"GeneZC/MiniMA-3B\", use_cache=True, device_map=\"auto\", torch_dtype=torch.float16).eval()\n",
    "# CPU.\n",
    "#model = AutoModelForCausalLM.from_pretrained(\"GeneZC/MiniMA-3B\", use_cache=True, device_map=\"cpu\", torch_dtype=torch.float16).eval()$\n",
    "# model.to('cuda')\n",
    "\n",
    "prompt = \"Question: Sherrie tells the truth. Vernell says Sherrie tells the truth. Alexis says Vernell lies. Michaela says Alexis tells the truth. Elanor says Michaela tells the truth. Does Elanor tell the truth?\\nAnswer: No\\n\\nQuestion: Kristian lies. Sherrie says Kristian lies. Delbert says Sherrie lies. Jerry says Delbert tells the truth. Shalonda says Jerry tells the truth. Does Shalonda tell the truth?\\nAnswer: No\\n\\nQuestion: Vina tells the truth. Helene says Vina lies. Kandi says Helene tells the truth. Jamey says Kandi lies. Ka says Jamey lies. Does Ka tell the truth?\\nAnswer: No\\n\\nQuestion: Christie tells the truth. Ka says Christie tells the truth. Delbert says Ka lies. Leda says Delbert tells the truth. Lorine says Leda tells the truth. Does Lorine tell the truth?\\nAnswer:\"\n",
    "input_ids = tokenizer([prompt]).input_ids\n",
    "output_ids = model.generate(\n",
    "    torch.as_tensor(input_ids).to('cuda'),\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    max_new_tokens=1024,\n",
    ")\n",
    "output_ids = output_ids[0][len(input_ids[0]):]\n",
    "output = tokenizer.decode(output_ids, skip_special_tokens=True).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data structure for a row in the dataset.\n",
    "from typing import List\n",
    "\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "\n",
    "\n",
    "class Row(BaseModel):\n",
    "    Description: str = Field(description=\"The description of the item\")\n",
    "    Category: str = Field(description=\"The category of the item\")\n",
    "    SubCategory: str = Field(description=\"The subcategory of the item\")\n",
    "\n",
    "def sythesise_sample(chain, samples: List[Row]):\n",
    "    # And a query intented to prompt a language model to populate the data structure.\n",
    "    sample_rows = \"TBC\"\n",
    "    row_query = \"generate a sample row for the dataset. \\n you can use the following categories: \\n\" + \"\\n\".join(data['Category'].unique()) \n",
    "    row_query = row_query + \"\\n you can use the following subcategories: \\n\" + \"\\n\".join(data['SubCategory'].unique())\n",
    "    row_query = row_query + \"\\n\" + \"here are some rows from the dataset: \\n\" + \"\\n\".join(sample_rows)\n",
    "    return chain.invoke({\"query\": row_query}) # not sure how this outputs as I haven't run it yet\n",
    "    \n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = PydanticOutputParser(pydantic_object=Row)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "sythesise_sample(chain, Row(Description=\"TBC\", Category=\"TBC\", SubCategory=\"TBC\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate samples for classes with less than 0.1 proportion of the major class\n",
    "target_proportion = 0.1\n",
    "major_class_counts = data['Category'].value_counts().max() # 135\n",
    "target_count = int(major_class_counts*target_proportion) # 13\n",
    "\n",
    "new_data = pd.DataFrame(columns=['Description', 'Category', 'SubCategory'])\n",
    "for category in data['Category'].unique():\n",
    "    category_data = data[data['Category'] == category]\n",
    "    # sythesise samples\n",
    "    i = target_count - len(category_data) \n",
    "    while i > 0:\n",
    "        # use list comprehension to convert dataframe to list of Row objects\n",
    "        samples = data[data['Category'] == category]\n",
    "        samples = [Row(Description=sample['Description'], Category=sample['Category'], SubCategory=sample['SubCategory']) for index, sample in samples.iterrows()]\n",
    "        # append sythesised samples to new_data\n",
    "        new_data = new_data.append(sythesise_sample(chain, samples)) # not sure if this is right tbh\n",
    "        i -= 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling - NOT IN USE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Resample the training set\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Oversample, then undersample the training set\n",
    "# def sample_strategy(df, target_proportion):\n",
    "#     major_class_counts = df.value_counts().max() # 135\n",
    "#     target_count = int(major_class_counts*target_proportion) # 13\n",
    "#     return {k: v if v>target_count else target_count for k, v in train['Category'].value_counts().to_dict().items()}\n",
    "# # Target a minimum class count of 10% of the majority class\n",
    "\n",
    "# # targeted oversampling not working\n",
    "# X_train, y_train = train[['Description']], train['Category']\n",
    "# oversampler = RandomOverSampler(sampling_strategy='auto', random_state=42)\n",
    "# # oversampler = RandomOverSampler(sampling_strategy=sample_strategy(X_train,0.1), random_state=42)\n",
    "# X_train, y_train = oversampler.fit_resample(train[['Description']], train['Category'])\n",
    "#undersampler = RandomUnderSampler(sampling_strategy=sample_strategy(X_train,-0.5), random_state=42)\n",
    "#X_train, y_train = undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# # join back because I don't want to refactor the notebook rn\n",
    "# train = pd.concat([X_train, y_train], axis=1)   \n",
    "# print(train.shape, val.shape, test.shape)\n",
    "# # save data\n",
    "# train.to_csv('data/train.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to measure distance \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# have a think about whether the data needs cleaning\n",
    "\n",
    "tfidf = TfidfVectorizer() # use token_pattern to remove punctuation if needed\n",
    "tfidf.fit(train['Description']) # val set not included here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import  confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "def evaluate(Y_true, Y_pred, dataset_name=\"Train\"):\n",
    "    # evaluate using the sklearn functions\n",
    "    precision = precision_score(Y_true, Y_pred, average='macro') #TP / (TP + FP)\n",
    "    recall = recall_score(Y_true, Y_pred, average='macro') #TP / (TP + FN)\n",
    "    f1_macro = f1_score(Y_true, Y_pred, average='macro')\n",
    "    f1 = f1_score(Y_true, Y_pred, average='weighted')\n",
    "    accuracy = accuracy_score(Y_true, Y_pred) #(TP + TN) / (TP + FP + FN + TN)\n",
    "    \n",
    "    # plot\n",
    "    print(dataset_name,\" Precision(macro):\", precision)\n",
    "    print(dataset_name,\" Recall(macro):\", recall)\n",
    "    print(dataset_name,\" F1 Score(macro):\", f1_macro)\n",
    "    print(dataset_name,\" F1 Score(weighted):\", f1)\n",
    "    print(dataset_name,\" Accuracy:\", accuracy)\n",
    "    \n",
    "def plot_confusion(Y_true, Y_pred, model, fig_name=\"confusion.png\"):\n",
    "    confusion = confusion_matrix(Y_true, Y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion, display_labels= model.classes_)\n",
    "    disp.plot(xticks_rotation=90)\n",
    "    plt.savefig('analysis/'+fig_name, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic SciKitLearn Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine distance\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "values = cosine_similarity(tfidf.transform(train['Description']).toarray(), tfidf.transform(train['Description']).toarray()) # dist() = x.y / (||x|| * ||y||) or sum(x * y) / (sqrt(sum(x^2)) * sqrt(sum(y^2)))\n",
    "similarities = pd.DataFrame(values, index=train.index, columns=train.index)\n",
    "\n",
    "# plot\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.heatmap(similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKLearn Models\n",
    "Testing the variety of models, SVM and Naive Bayes worked the best on the raw data, while KNN and RF didn't work as well as expected.\n",
    "All models suffered from the distibution issue in the datset, only predicting the most common classes (food and entertainment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# setup KNN\n",
    "k = int(np.sqrt(train['Category'].count())) # sqrt(n) is a common choice for k\n",
    "knn = KNeighborsClassifier(n_neighbors=k, metric='cosine')\n",
    "knn.fit(tfidf.transform(train['Description']).toarray(), train['Category'])\n",
    "\n",
    "# predict\n",
    "train_accuracy = cross_val_score(knn, tfidf.transform(train['Description']).toarray(), train['Category'], cv=5, scoring='accuracy')\n",
    "val_hat = knn.predict(tfidf.transform(val['Description']).toarray())\n",
    "\n",
    "# evaluate\n",
    "print(\"training accuracy:\", train_accuracy.mean())\n",
    "evaluate(val['Category'], val_hat, \"Val\")\n",
    "plot_confusion(val['Category'], val_hat, knn, \"confusion_matricies/knn.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# prepare data labels to be numerical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(train['Category'])\n",
    "train_Y = le.transform(train['Category'])\n",
    "val_Y = le.transform(val['Category'])\n",
    "\n",
    "# setup SVM\n",
    "svm = SVC(kernel='linear')\n",
    "svm.fit(tfidf.transform(train['Description']).toarray(), train_Y)\n",
    "\n",
    "# predict\n",
    "train_accuracy = cross_val_score(svm, tfidf.transform(train['Description']).toarray(), train['Category'], cv=5, scoring='accuracy')\n",
    "val_hat = svm.predict(tfidf.transform(val['Description']).toarray())\n",
    "\n",
    "# evaluate\n",
    "print(\"training accuracy:\", train_accuracy.mean())\n",
    "evaluate(val_Y, val_hat, \"Val\")\n",
    "plot_confusion(val_Y, val_hat, svm, \"confusion_matricies/svm.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. HuggingFace Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MiniLM encoding; full guide: https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\n",
    "import pandas as pd \n",
    "from sentence_transformers import SentenceTransformer\n",
    "sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(train['Description'].values)\n",
    "\n",
    "assert len(embeddings) == train['Description'].count() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE / ADASYN synthetic oversampling\n",
    "This method is really promising, and had a big effect when used on the categories with enough data, but there just isn't enough data to make it work well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE - requires more than 6 samples \n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "train_X, train_y = smote.fit_resample(embeddings, train['Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADASYN - requires more than 6 samples \n",
    "from imblearn.over_sampling import ADASYN\n",
    "adasyn = ADASYN(sampling_strategy='auto', random_state=42)\n",
    "train_X, train_y = adasyn.fit_resample(embeddings, train['Category'])\n",
    "train = pd.concat(train_X, train_y, axis=1)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Models on Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN on embeddings\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# setup KNN\n",
    "k = int(np.sqrt(train['Category'].count())) # sqrt(n) is a common choice for k\n",
    "knn = KNeighborsClassifier(n_neighbors=k, metric='cosine')\n",
    "knn.fit(embeddings, train['Category']) # should still have the same indicies\n",
    "\n",
    "# predict\n",
    "train_y_hat = knn.predict(model.encode(train['Description'].values))\n",
    "val_hat = knn.predict(model.encode(val['Description'].values))\n",
    "test_hat = knn.predict(model.encode(test['Description'].values))\n",
    "\n",
    "# evaluate\n",
    "#evaluate(train['Category'], train_hat, \"Test\")\n",
    "evaluate(val['Category'], val_hat, \"Val\")\n",
    "plot_confusion(val['Category'], val_hat, knn, \"confusion_matricies/knn_embeddings.png\")\n",
    "evaluate(test['Category'], test_hat, \"Test\")\n",
    "plot_confusion(test['Category'], test_hat, knn, \"confusion_matricies/knn_embeddings_test.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM on embeddings\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# setup SVM\n",
    "svm = SVC(kernel='linear')\n",
    "svm.fit(embeddings, train['Category'])\n",
    "\n",
    "# predict\n",
    "val_embeddings = model.encode(val['Description'].values)\n",
    "train_hat = svm.predict(embeddings)\n",
    "val_hat = svm.predict(val_embeddings)\n",
    "test_hat = svm.predict(model.encode(test['Description'].values))\n",
    "\n",
    "# Evaluate\n",
    "#evaluate(train['Category'], train_hat, \"Test\")\n",
    "evaluate(val['Category'], val_hat, \"Val\")\n",
    "plot_confusion(val['Category'], val_hat, knn, \"confusion_matricies/svm_embeddings.png\")\n",
    "evaluate(test['Category'], test_hat, \"Test\")\n",
    "plot_confusion(test['Category'], test_hat, knn, \"confusion_matricies/svm_embeddings_test.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM on embeddings subcategories\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# prepare data labels to be numerical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "cat_le = LabelEncoder()\n",
    "cat_le.fit(train['Category'])\n",
    "train_cat = cat_le.transform(train['Category'])\n",
    "val_cat = cat_le.transform(val['Category'])\n",
    "\n",
    "subcat_le = LabelEncoder()\n",
    "# unique values of subcategories\n",
    "subcats = np.append(train['Sub_Category'].unique(), \"Unknown\")\n",
    "subcat_le.fit(subcats)\n",
    "train_Y = subcat_le.transform(train['Sub_Category'])\n",
    "val['Sub_Category'] = [subcat if subcat in subcats else \"Unknown\" for subcat in val['Sub_Category']]\n",
    "val_Y = subcat_le.transform(val['Sub_Category'])\n",
    "\n",
    "#concat train_Y to final column in embeddings\n",
    "#embeddings = np.concatenate((embeddings, train_cat), axis=1)\n",
    "embeddings = np.column_stack((embeddings, train_cat))\n",
    "val_embeddings = model.encode(val['Description'].values)\n",
    "val_embeddings = np.column_stack((val_embeddings, val_cat))\n",
    "\n",
    "# setup\n",
    "n_svm = SVC(kernel='linear')\n",
    "n_svm.fit(embeddings, train_Y)\n",
    "\n",
    "# predict\n",
    "train_y_hat = n_svm.predict(embeddings)\n",
    "val_Y_hat = n_svm.predict(val_embeddings)\n",
    "\n",
    "# Evaluate\n",
    "#evaluate(train['Category'], train_hat, \"Test\")\n",
    "evaluate(val_Y, val_Y_hat, \"Val\")\n",
    "plot_confusion(val_Y, val_Y_hat, n_svm, \"confusion_matricies/svm_embeddings_subcategories.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "# SVM with class weights on embeddings\n",
    "# setup\n",
    "total = train['Category'].count()\n",
    "class_weights = {k: 1-(v/total) for k, v in train['Category'].value_counts().to_dict().items()}\n",
    "svm = SVC(kernel='linear', class_weight=class_weights)\n",
    "svm.fit(embeddings, train['Category'])\n",
    "\n",
    "# cross validate\n",
    "scores = cross_val_score(svm, embeddings, train['Category'], cv=5)\n",
    "\n",
    "# predict\n",
    "train_hat = svm.predict(embeddings)\n",
    "val_embeddings = model.encode(val['Description'].values)\n",
    "val_hat = svm.predict(val_embeddings)\n",
    "test_hat = svm.predict(model.encode(test['Description'].values))\n",
    "# Evaluate\n",
    "#evaluate(train['Category'], train_hat, \"Test\")\n",
    "evaluate(val['Category'], val_hat, \"Val\")\n",
    "plot_confusion(val['Category'], val_hat, knn, \"confusion_matricies/svm_embeddings_weights.png\")\n",
    "evaluate(test['Category'], test_hat, \"Test\")\n",
    "plot_confusion(test['Category'], test_hat, knn, \"confusion_matricies/svm_embeddings_test_weights.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
