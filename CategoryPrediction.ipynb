{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Current Plan\n",
    "1. Create a function to calculate the distance between descriptions, use that function to naively classify new descriptions. probably looks something like a search function.\n",
    "2. Grab a text classification model of hugging face and fine-tune it on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup requirements, which aren't loading in the venv for some reason\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "with open('data/Datas.csv') as file:\n",
    "    data = pd.read_csv(file)\n",
    "    \n",
    "# Split data into training and testing sets in a stratified way, despite the minimum class only having 2 samples \n",
    "cat_count = data.value_counts('Category')\n",
    "subcat_count = data.value_counts(['Category', 'Sub_Category'])\n",
    "\n",
    "# handle the case where the minimum class has only 2 samples\n",
    "data = data.groupby('Category').filter(lambda x: len(x) > 2) # this method works, but my pandas is pretty rusty. \n",
    "\n",
    "train, test = train_test_split(data, test_size=0.2, stratify=data['Category'], random_state=42) # random_state for reproducibility\n",
    "train, val = train_test_split(train, test_size=0.3, stratify=train['Category'], random_state=77) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Calculating distance \n",
    "Cosine similarity [shouldn't be affected by text length](https://nikoskalikis.medium.com/text-similarity-euclidian-distance-vs-cosine-similarity-3a1167f686a#:~:text=Cosine%20similarity%20is%20an%20important,value%20between%20%2D1%20and%201.), which is quite short here. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to measure distance \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# have a think about whether the data needs cleaning\n",
    "\n",
    "\n",
    "tfidf = TfidfVectorizer() # use token_pattern to remove punctuation if needed\n",
    "tfidf.fit(train['Description']) # val set not included here \n",
    "tfidf_array = tfidf.transform(train['Description']).toarray()\n",
    "\n",
    "data2 = pd.DataFrame(tfidf_array, \n",
    "                     columns=tfidf.get_feature_names_out(),\n",
    "                     index=train['Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine distance\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "values = cosine_similarity(data2, data2) # dist() = x.y / (||x|| * ||y||) or sum(x * y) / (sqrt(sum(x^2)) * sqrt(sum(y^2)))\n",
    "output = pd.DataFrame(values, index=train.index, columns=train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.heatmap(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2. Models\n",
    "I can use a variety of basic models, I'll stick with KNN and Naive Bayes since they are simple and known to work on text. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# setup KNN\n",
    "k = int(np.sqrt(train['Category'].count())) # sqrt(n) is a common choice for k\n",
    "knn = KNeighborsClassifier(n_neighbors=k, metric='cosine')\n",
    "knn.fit(data2, train['Category'])\n",
    "\n",
    "# predict\n",
    "#predictions = knn.predict(tfidf.transform(val['Description']).toarray())\n",
    "#tmp = pd.DataFrame(predictions, index=val.index, columns=['Predicted'])\n",
    "#val_pred = val.join(tmp)\n",
    "\n",
    "# evaluate\n",
    "accuracies = cross_val_score(knn, data2, train['Category'], cv=5)\n",
    "print(\"Train Score:\", np.mean(accuracies))\n",
    "print(\"Test Score:\", knn.score(tfidf.transform(val['Description']).toarray(), val['Category']))\n",
    "\n",
    "\n",
    "# evaluate accuracy and precision metrics\n",
    "\n",
    "#print(\"Test Score:\", knn.score( predictions))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
